/**
 * <h2>Java 内存模型 Java Memory Model</h2>
 * 
 * <h3>并发编程的背景</h3>
 * 两个关键问题
 * <ul>
 * 		<li>1，线程之间如何通信 <p>
 * 		</li>
 * 		<li>2，线程之间如何同步，<p>
 * 		控制不同线程间操作发生相对顺序的机制</li>
 * </ul>
 * 
 * 两种通信机制
 * <ul>
 * 		<li>1，共享内存</li>
 * 		<li>2，消息传递</li>
 * </ul>
 * 在共享内存中，通过写-读内存中的公共状态通信；在消息传递中，必须显式地通过消息来通信
 * <p>
 * 共享内存中，必须显式指定在线程之间需要互斥的代码；而在消息传递中，同步是附着消息隐式进行
 * 
 * <h3>1，平台的内存模型</h3>
 * 在共享内存的多处理器体系中，每个处理器都拥有自己的缓存，并定期与主内存进行协调。
 * <p>
 * 缓存与主存是通过缓存一致性来进行协调，而不同的处理器有不同的级别，JMM屏蔽这个差异
 * 
 * <h3>2，重排序</h3>
 * 编译器和处理器为了优化程序性能会对指令序列进行重新排序的手段
 * <ul>
 * 		<li>1，as-if-serial <p>
 * 		针对单线程，编译器和处理器不会对存在数据依赖关系的操作做重排序</li>
 * 		<li>2，编译器重排序 <p>
 * 		在满足as-if-serial的前提下，对语句重新排序</li>
 * 		<li>3.1，处理器重排序 - 指令级并行的重排序 <p>
 * 		处理器通过指令级并行技术将多条指令并行重叠执行</li>
 * 		<li>3.2，处理器重排序 - 内存系统的重排序 <p>
 * 		由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去是无序的</li>
 * </ul>
 * 
 * <h3>顺序一致性</h3>
 * 如果存在数据竞争时，程序的执行往往产生违反直觉的结果。如果程序是正确同步的，程序的执行将具有
 * 顺序一致性。<p>即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同。
 * <p>
 * 1，顺序一致性内存模型
 * <p>
 * 顺序一致性内存模型的两大特性
 * <ul>
 * 		<li>所有线程的操作都必须确保在整体的操作上看到的顺序是同当前线程的操作顺序是一致的</li>
 * 		<li>所有的线程都只能看到一个单一的操作执行顺序，即每个操作都是原子执行且对所有线程可见</li>
 * </ul>
 * 
 * <h3>volatile 的内存语义</h3>
 * volatile 的特性
 * <ul>
 * 		<li>原子性，单个 volatile 变量的读或写都是原子操作</li>
 * 		<li>可见性，对一个 volatile 变量的读，总是能看见这个 volatile 变量的最后写入</li>
 * </ul>
 * volatile 写-读的内存语义
 * <ul>
 * 		<li>1，线程 A 写一个 volatile 变量，然后向将要读这个 volatile 变量的线程发出通知 </li>
 * 		<li>2，要读取这个 volatile 变量的读线程在接收到通知后，本地内存的变量会被置为无效。<p>
 * 		此时，读线程必须从主内存读取变量。</li>
 * 		<li>3，这个通知实质上线程 A 通过主内存向其他要读取 volatile 变量的线程发送的</li>
 * </ul>
 * volatile 内存语义的实现
 * <p>
 * volatile 重排序规则
 * <ul>
 * 		<li>当第二个操作是 volatile 写时，不论第一个操作是什么，都不能重排序。</li>
 * 		<li>当第一个操作是 volatile 读时，不论第二个操作是什么，都不能重排序。</li>
 * 		<li>当第一个操作是 volatile 写时，第二个操作是 volatile 读时，不能重排序。</li>
 * </ul>
 * 
 * 基于保守策略的 JMM 内存屏障插入策略
 * <ul>
 * 		<li>在每个 volatile 写操作的前面插入一个 StoreStore 屏障</li>
 * 		<li>在每个 volatile 写操作的后面插入一个 StoreLoad 屏障</li>
 * 		<li>在每个 volatile 读操作的后面插入一个 LoadLoad 屏障</li>
 * 		<li>在每个 volatile 读操作的后面插入一个 LoadStore 屏障</li>
 * </ul>
 * 
 * volatile 语义的增强
 * 
 * <h3>Lock 锁的内存语义</h3>
 * 锁的释放和获取对应的内存语义
 * <p>
 * 锁释放与 volatile 写有相同的内存语义，锁获取与 volatile 读有相同的内存语义。
 * <ul>
 * 		<li>1，线程 A 释放一个锁时，会将该线程本地内存中的共享变量刷新到主内存中，
 * 		然后线程 A 会向下一个获取到锁的线程发送通知。</li>
 * 		<li>2，线程 B 获取一个锁时，接收到通知后 JMM 将线程本地内存的共享变量置为无效，
 * 		使得被监视器保护的临界区代码必须从主内存读取共享变量。</li>
 * 		<li>3，这个通知实质上线程 A 通过主内存向线程 B 发送的</li>
 * </ul>
 * 
 * 锁的内存语义的实现
 * <p>
 * 加锁方法 lock() 会首先读取 volatile 变量 state，解锁方法 unlock() 会最后写 volatile 变量 state。
 * <p>
 * 释放锁的线程在写 volatile 变量之前的共享变量，在获取锁的线程读取同一个 volatile 变量后将立即
 * 变得对获取锁的线程可见。
 * <p>
 * CAS 如果当前状态值等于预期值，则以原子方式将同步状态设置为给定的更新值，此操作具有
 *  volatile 相同的读与写的内存语义。
 * <p>
 * compareAndSetState(int expect, int update) 在 intel 的手册中说明使用缓冲锁替代总线锁来
 * 保证对内存的读-改-写操作原子执行，同时禁止该操作与之前和之后的读写指令重排序，最后将
 * 写缓冲区内的所有数据刷新到主内存中。
 * 
 * <h3>Final 域的内存语义</h3>
 * Final 域的重排序规则
 * <ul>
 * 		<li>写 Final 域的重排序规则 <p>在构造器内对 final 域的写入，与随后将构造对象的引用
 * 		赋值给一个引用变量，这两个操作之间不能重排序。</li>
 * 		<li>读 Final 域的重排序规则 <p>初次读一个包含 final 域的对象的引用，与
 * 		随后读取 final 域，这两个操作不能重排序。</li>
 * </ul>
 * 
 * 确保 Final 引用不能在构造函数逸出
 * <p>
 * 在写 Final 域的重排序规则中，被构造对象的引用不能为其他线程所见。
 * 
 * Final 语义的增强
 * <p>
 * 旧的内存模型中，最严重的缺陷是线程看到的 final 域的值会改变。在 JSR-133 中增加 
 * Final 域的重排序规则，就可以提供初始化安全保证。
 * 
 * <h3>3，JSR-133 内存模型简介</h3>
 * happens-before的定义
 * <ul>
 * 		<li>1，JMM对于程序员的承诺 <p>
 * 		操作A happens-before 操作B，那么A的结果对于B可见，且A的执行顺序在B之前</li>
 * 		<li>2，JMM对编译器和处理器的约束原则 <p>
 * 		如果不改变正确同步的多线程程序的执行结果，编译器和处理器可以随意优化</li>
 * </ul>
 * happens-before的规则
 * <ul>
 * 		<li>1，程序顺序规则 <p>
 * 		如果程序中，A happens-before B，那么在线程中，A 也是 happens-before B</li>
 * 		<li>2，监视器锁规则 <p>
 * 		一个锁的解锁操作位于这个锁的加锁操作之后</li>
 * 		<li>3，volatile变量规则 <p>
 * 		对于volatile变量的写操作位于读操作之后</li>
 * 		<li>4，传递性 <p>
 * 		如果A happens-before B，且 B happens-before C，那么 A happens-before C</li>
 * 		<li>5，线程 start 规则 <p>
 * 		若线程A中执行 ThreadB.start()，那么在线程A中启动线程B前的操作都先于线程B中其他操作</li>
 * 		<li>6，线程 join 规则 <p>
 * 		若线程A中执行 ThreadB.join()，那么线程B的操作都先于线程A从 join() 成功返回</li>
 * </ul>
 * 
 */
package org.self.jmm;
